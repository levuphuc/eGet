# -*- coding: utf-8 -*-
# ============================================================================
# C·∫§U H√åNH - THAY ƒê·ªîI URL ·ªû ƒê√ÇY
# ============================================================================
TARGET_URL = "https://tuesy.net/phat-day-chan-trau/"  # ‚Üê Test v·ªõi URL ƒë∆°n gi·∫£n tr∆∞·ªõc
# ============================================================================

import sys
import os
sys.stdout.reconfigure(encoding='utf-8')
import requests
import json
from datetime import datetime

def scrape_page():
    api_url = "http://localhost:8000/api/v1/scrape"
    
    # Configure scraping options v·ªõi c·∫£i thi·ªán cho Cloudflare
    payload = {
        "url": TARGET_URL,
        "formats": ["markdown", "html"],
        "onlyMainContent": True,
        "includeScreenshot": False,
        "includeRawHtml": False,
        "waitFor": 30000,  # TƒÉng th·ªùi gian ch·ªù l√™n 30 gi√¢y cho Cloudflare
        "timeout": 120,    # TƒÉng timeout request l√™n 2 ph√∫t
        "extract": {
            "custom_config": {
                "remove_ads": True,
                "extract_tables": True,
                "handle_cloudflare": True,
                "max_retries": 3
            }
        },
        "headers": {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8",
            "Accept-Language": "vi-VN,vi;q=0.9,en-US;q=0.8,en;q=0.7",
            "Accept-Encoding": "gzip, deflate, br",
            "Cache-Control": "no-cache",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Sec-Fetch-User": "?1"
        },
        "proxy": None,
        "stealth": True,
        "actions": [
            {"type": "wait", "selector": "body", "milliseconds": 5000},
            {"type": "scroll", "selector": "body", "direction": "down", "amount": 500, "milliseconds": 1000},
            {"type": "wait", "selector": "body", "milliseconds": 3000}
        ]
    }
    
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ƒêang g·ª≠i request ƒë·∫øn: {api_url}")
    print(f"[{datetime.now().strftime('%H:%M:%S')}] URL c·∫ßn crawl: {TARGET_URL}")
    print("-" * 80)
    
    try:
        response = requests.post(api_url, json=payload, timeout=150)  # TƒÉng timeout l√™n 2.5 ph√∫t
        
        # Ki·ªÉm tra status code
        print(f"[{datetime.now().strftime('%H:%M:%S')}] Status Code: {response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            
            if result.get("success"):
                print(f"[{datetime.now().strftime('%H:%M:%S')}] SUCCESS: Crawl th√†nh c√¥ng!")
                print("-" * 80)
                
                # Access extracted content
                data = result.get("data", {})
                markdown_content = data.get("markdown", "")
                html_content = data.get("html", "")
                metadata = data.get("metadata", {})
                structured_data = data.get("structured_data", {})
                
                # In th√¥ng tin metadata
                print("\nMETADATA:")
                print(f"  - Title: {metadata.get('title', 'N/A')}")
                print(f"  - Description: {metadata.get('description', 'N/A')}")
                print(f"  - Language: {metadata.get('language', 'N/A')}")
                print(f"  - URL: {metadata.get('url', 'N/A')}")
                
                # In preview n·ªôi dung Markdown
                print("\nNOI DUNG MARKDOWN (500 k√Ω t·ª± ƒë·∫ßu):")
                print("-" * 40)
                if markdown_content:
                    print(markdown_content[:500])
                    print("..." if len(markdown_content) > 500 else "")
                else:
                    print("Kh√¥ng c√≥ n·ªôi dung markdown")
                
                # Th·ªëng k√™
                print("\nTHONG KE:")
                print(f"  - ƒê·ªô d√†i Markdown: {len(markdown_content)} k√Ω t·ª±")
                print(f"  - ƒê·ªô d√†i HTML: {len(html_content)} k√Ω t·ª±")
                print(f"  - C√≥ structured data: {'C√≥' if structured_data else 'Kh√¥ng'}")
                
                # T·ª± ƒë·ªông l∆∞u k·∫øt qu·∫£ v√†o file
                print("\nT·ª± ƒë·ªông l∆∞u k·∫øt qu·∫£...")
                save_results(result, TARGET_URL)
                
                return result
            else:
                print(f"[{datetime.now().strftime('%H:%M:%S')}] ERROR: Crawl th·∫•t b·∫°i!")
                print(f"Error: {result.get('error', 'Unknown error')}")
                print(f"Full response: {json.dumps(result, indent=2, ensure_ascii=False)[:1000]}")
                
        else:
            print(f"ERROR: L·ªói HTTP: {response.status_code}")
            print(f"Response: {response.text[:500]}")
            
    except requests.exceptions.ConnectionError:
        print(f"ERROR: Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server!")
        print("H√£y ƒë·∫£m b·∫£o r·∫±ng:")
        print("1. Server eGet-Crawler ƒëang ch·∫°y (npm start)")
        print("2. Server ƒëang l·∫Øng nghe ·ªü port 8000")
        print("3. Kh√¥ng c√≥ firewall ch·∫∑n k·∫øt n·ªëi")
        
    except requests.exceptions.Timeout:
        print(f"ERROR: Request timeout sau 150 gi√¢y!")
        print("Website c√≥ th·ªÉ m·∫•t qu√° l√¢u ƒë·ªÉ load ho·∫∑c server qu√° t·∫£i.")
        
    except Exception as e:
        print(f"ERROR: L·ªói kh√¥ng x√°c ƒë·ªãnh: {str(e)}")
    
    return None

def save_results(result, url):
    """L∆∞u k·∫øt qu·∫£ crawl v√†o file"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # T·∫°o t√™n file t·ª´ URL
    try:
        # L·∫•y ph·∫ßn cu·ªëi c·ªßa URL l√†m t√™n file
        url_part = url.rstrip('/').split('/')[-1]
        if not url_part or url_part == url.split('//')[-1].split('/')[0]:
            url_part = "crawled_content"
    except:
        url_part = "crawled_content"
    
    data = result.get("data", {})
    metadata = data.get("metadata", {})
    
    # L∆∞u Markdown v·ªõi format ƒë·∫πp
    markdown_content = data.get("markdown", "")
    if markdown_content:
        md_filename = f"{url_part}_{timestamp}.md"
        with open(md_filename, 'w', encoding='utf-8') as f:
            f.write(f"# {metadata.get('title', 'Tuesy.net Content')}\\n\\n")
            f.write(f"**URL**: {url}\\n")
            f.write(f"**Crawl time**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n")
            f.write(f"**Duration**: Completed successfully\\n\\n")
            f.write("---\\n\\n")
            f.write(markdown_content)
        print(f"‚úÖ SUCCESS: ƒê√£ l∆∞u Markdown v√†o: {md_filename}")
    
    # L∆∞u JSON ƒë·∫ßy ƒë·ªß (optional)
    json_filename = f"{url_part}_full_{timestamp}.json"
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"üìÑ SUCCESS: ƒê√£ l∆∞u JSON v√†o: {json_filename}")

def test_server_connection():
    """Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn server"""
    print("\nKi·ªÉm tra k·∫øt n·ªëi server...")
    try:
        response = requests.get("http://localhost:8000/health", timeout=5)
        print(f"Response status: {response.status_code}")
        if response.status_code == 200:
            print("SUCCESS: Server ƒëang ho·∫°t ƒë·ªông!")
            return True
    except Exception as e:
        print(f"Connection error: {e}")
    
    print("ERROR: Kh√¥ng th·ªÉ k·∫øt n·ªëi ƒë·∫øn server!")
    return False

if __name__ == "__main__":
    print("=" * 80)
    print("EGET-CRAWLER TEST SCRIPT")
    print("=" * 80)
    
    # Ki·ªÉm tra server tr∆∞·ªõc
    if test_server_connection():
        print("\nB·∫Øt ƒë·∫ßu crawl d·ªØ li·ªáu...")
        print("=" * 80)
        scrape_page()
    else:
        print("\nWARNING: H∆∞·ªõng d·∫´n kh·ªüi ƒë·ªông server:")
        print("1. M·ªü terminal m·ªõi")
        print("2. Cd ƒë·∫øn th∆∞ m·ª•c eGet-Crawler-for-ai")
        print("3. Ch·∫°y l·ªánh: npm start")
        print("4. ƒê·ª£i server kh·ªüi ƒë·ªông xong (th∆∞·ªùng ·ªü port 8000)")
        print("5. Ch·∫°y l·∫°i script n√†y")
    
    print("\n" + "=" * 80)
    print("Ho√†n th√†nh!")